# Tips and Tricks
___


### K-Nearest Neighbor classifier

#### Level up your numpy

You'll realize after going through the first question that a strong understanding of numpy will be essential.  Jake VanderPlas is one of my favorite data scientist to follow when it comes to numpy.  Check out his fantastic talk on [how you can speed up your python code with numpy](https://www.youtube.com/watch?v=EEUXKG97YRw).

__For the hardcore__
> For help optimizing your KNN classifier, check out Christian Bauckhage's work on numpy and scipy.  Especially his papers on [Computing Nearest Neighbors](https://multimedia-pattern-recognition.info/fileadmin/Websites/mmprec/uploads/docs/Bauckhage/np-sp-rec-edm.pdf) and [Squared Euclidean Distance Matrices](https://www.researchgate.net/publication/266617010_NumPy_SciPy_Recipes_for_Data_Science_Squared_Euclidean_Distance_Matrices?channel=doi&linkId=543598a70cf2643ab9867c26&showFulltext=true).


### Training a Support Vector Machine

> The IPython Notebook svm.ipynb will walk you through implementing the SVM classifier.


### Implement a Softmax classifier

> The IPython Notebook softmax.ipynb will walk you through implementing the Softmax classifier.

### Two-Layer Neural Network

> The IPython Notebook two_layer_net.ipynb will walk you through the implementation of a two-layer neural network classifier.

### Higher Level Representations: Image Features

> The IPython Notebook two_layer_net.ipynb will walk you through the implementation of a two-layer neural network classifier.

